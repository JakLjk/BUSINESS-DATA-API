# INFO
## <ip> can be set to the docker name that is running the
## service in the current compose stack

# LOGGING CONFIGURATION
## Streaming Handler Log
LOG_LEVEL_STREAMING=debug
## PostgreSQL Handler Log
LOG_TO_POSTGRE_SQL=1
LOG_LEVEL_POSTGRE_SQL=debug

# REDIS CONFIGURATION
## Redis server ulr
REDIS_HOST=redis://<ip>
REDIS_PORT=6379/0
## Redis worker configuration
### Max size of scraping batch (i.e. how many files can be scraped by one worker)
SCRAPE_BATCH_SIZE=40
### After how much time job should be marked as stale
STALE_JOB_TRESHOLD_SECONDS=600

# POSTGRESQL CONFIGURATION
## PSQL DB used by Flask API to store scraped information
POSTGRES_HOST=<ip>
POSTGRES_PORT=5432
POSTGRES_USER=<user>
POSTGRES_PASSWORD=<password>
POSTGRES_DATABASE=<db_name>
## PSQL DB used by Spark sink to store transformed data
PSQLD_SPARK_WRITE_TO_DB_HOST=<ip>
PSQLD_SPARK_WRITE_TO_DB_PORT=5432
PSQLD_SPARK_WRITE_TO_DB_USER=<user>
PSQLD_SPARK_WRITE_TO_DB_PASSWORD=<password>
PSQLD_SPARK_WRITE_TO_DB_DATABASE=<db_name>
PSQLD_SPARK_WRITE_TO_DD_SCHEME=public
## Kafka conenction string (used by kafka/debezium-enabled postgres to stream data to spark)
PSQLD_KAFKA_STREAM_HOST=<ip>
PSQLD_KAFKA_STREAM_PORT=9092
PSQLD_KAFKA_STREAM_SOURCE=postgres.public.raw_krs_api_full_extract

# SPARK STREAM CONFIGURATION
### KRS API Stream spark compute engine
KRSAPI_SPARK_ENGINE_HOST=spark://<ip>
KRSAPI_SPARK_ENGINE_PORT=7077
KRSAPI_SPARK_ENGINE_CHECKPOINT_PATH=./spark_etl/checkpoints/krsapi_checkpoint/checkpoint_file
SPARK_EXECUTOR_MEMORY=4g
SPARK_EXECUTOR_CORES=4

# DOCKER CONFIG
## Absolute path to the host dir where spark checkpoints should be stored
DOCKER_PERSISTENT_CHECKPOINT_PATH=<host_path>