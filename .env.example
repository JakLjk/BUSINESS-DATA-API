# LOGGING CONFIGURATION
## Streaming Handler Log
LOG_LEVEL_STREAMING = "debug"
## PostgreSQL Handler Log
LOG_TO_POSTGRE_SQL = 1
LOG_LEVEL_POSTGRE_SQL = "debug"

# REDIS CONFIGURATION
## Redis server ulr
REDIS_HOST = "redis://redis"
REDIS_PORT = "6379/0"
## Redis worker configuration
### Max size of scraping batch (i.e. how many files can be scraped by one worker)
SCRAPE_BATCH_SIZE = 40
### After how much time job should be marked as stale
STALE_JOB_TRESHOLD_SECONDS = 600

# POSTGRESQL CONFIGURATION
## PSQL DB used by Flask API to store scraped information
POSTGRES_HOST=192.168.0.12
POSTGRES_PORT=5432
POSTGRES_USER=docker
POSTGRES_PASSWORD=docker
POSTGRES_DATABASE=database
## PSQL DB used by Spark sink to store transformed data
PSQLD_SPARK_WRITE_TO_DB_HOST= "192.168.0.12"
PSQLD_SPARK_WRITE_TO_DB_PORT="5432"
PSQLD_SPARK_WRITE_TO_DB_USER = "docker"
PSQLD_SPARK_WRITE_TO_DB_PASSWORD = "docker"
PSQLD_SPARK_WRITE_TO_DB_DATABASE = "database"
PSQLD_SPARK_WRITE_TO_DD_SCHEME = "public"
## Kafka conenction string (used by kafka/debezium-enabled postgres to stream data to spark)
PSQLD_KAFKA_STREAM_HOST = "192.168.0.12"
PSQLD_KAFKA_STREAM_PORT = "9092"

# SPARK STREAM CONFIGURATION
### KRS API Stream spark compute engine
KRSAPI_SPARK_ENGINE_HOST="spark://192.168.0.12"
KRSAPI_SPARK_ENGINE_PORT="7077"
KRSAPI_SPARK_ENGINE_CHECKPOINT_PATH="./spark_etl/checkpoints/krsapi_checkpoint/checkpoint_file"

